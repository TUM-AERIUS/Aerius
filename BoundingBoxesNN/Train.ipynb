{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Train CNN to predict bounding boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import BB_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify train parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "num_train = 6\n",
    "batch_size = 2\n",
    "log_every = 1\n",
    "num_val = 1\n",
    "save_every = num_train // batch_size\n",
    "\n",
    "num_iter = epochs * (num_train // batch_size)\n",
    "\n",
    "starter_learning_rate = 1e-5\n",
    "learning_decay_rate = 0.65\n",
    "use_dropout = False\n",
    "\n",
    "filename_log = 'log.csv'\n",
    "\n",
    "image_width = 224\n",
    "image_height = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load train dataset\n",
    "dataset_train = tf.data.TFRecordDataset('train.record')\n",
    "dataset_train = dataset_train.concatenate(tf.data.TFRecordDataset('train_flipped.record'))\n",
    "dataset_train = dataset_train.concatenate(tf.data.TFRecordDataset('val.record'))\n",
    "dataset_train = dataset_train.concatenate(tf.data.TFRecordDataset('val_flipped.record'))\n",
    "dataset_train = dataset_train.shuffle(buffer_size=10000)\n",
    "dataset_train = dataset_train.batch(batch_size)\n",
    "dataset_train = dataset_train.repeat()\n",
    "iterator_train = dataset_train.make_initializable_iterator()\n",
    "next_element_train = iterator_train.get_next()\n",
    "\n",
    "# Load validation dataset\n",
    "dataset_val = tf.data.TFRecordDataset('test.record')\n",
    "dataset_val = dataset_val.concatenate(tf.data.TFRecordDataset('test_flipped.record'))\n",
    "dataset_val = dataset_val.shuffle(buffer_size=1000)\n",
    "dataset_val = dataset_val.batch(batch_size)\n",
    "dataset_val = dataset_val.repeat()\n",
    "iterator_val = dataset_val.make_initializable_iterator()\n",
    "next_element_val = iterator_val.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up log files\n",
    "log_file = open(filename_log, 'w', 1)\n",
    "log_file.write('iteration,train loss,train pred acc,train bb mean abs err,val loss,val pred acc,val bb mean abs err\\n')\n",
    "err_file = open('error.log', 'w', 1)\n",
    "\n",
    "config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "with tf.Session(config=config) as sess:\n",
    "    # Create network\n",
    "    bb_net = BB_CNN.BB_CNN(kernel_size = 13 * [3], kernel_stride = 13 * [1],\n",
    "                           num_filters =  2 * [64] + 2 * [128] + 3 * [256] + 6 * [512],\n",
    "                           pool_size = 2 * [1, 2] + 3 * [1, 1, 2], pool_stride = 2 * [1, 2] + 3 * [1, 1, 2],\n",
    "                           hidden_dim = 2 * [4096], dropout = 0.5, weight_decay_bb = 0.0, weight_scale = 1e-3,\n",
    "                           file_name = 'vgg16.npy', loss_bb_weight = 1.0)\n",
    "    \n",
    "    # Build computational graph and calculate loss\n",
    "    images = tf.placeholder(tf.float32, [batch_size, image_width, image_height, 3])\n",
    "    train_mode = tf.placeholder(tf.bool)\n",
    "    target_prob = tf.placeholder(tf.float32, [batch_size])\n",
    "    target_bb = tf.placeholder(tf.float32, [batch_size, 4])\n",
    "    bb_net.build(images, train_mode)\n",
    "    bb_net.predict()\n",
    "    bb_net.loss(target_prob, target_bb)\n",
    "    \n",
    "    # Build graph for parsing\n",
    "    # Define features for parsing the TFRecord file\n",
    "    feature = {'image/encoded': tf.FixedLenFeature([], tf.string),\n",
    "               'image/object/bbox/xmin': tf.FixedLenSequenceFeature([], tf.float32, allow_missing=True, default_value = -1.),\n",
    "               'image/object/bbox/xmax': tf.FixedLenSequenceFeature([], tf.float32, allow_missing=True, default_value = 0.),\n",
    "               'image/object/bbox/ymin': tf.FixedLenSequenceFeature([], tf.float32, allow_missing=True, default_value = -1.),\n",
    "               'image/object/bbox/ymax': tf.FixedLenSequenceFeature([], tf.float32, allow_missing=True, default_value = 0.)}\n",
    "    next_example = tf.placeholder(tf.string, [batch_size])\n",
    "    parser = tf.parse_example(next_example, features=feature)\n",
    "    \n",
    "    # Build graph for image decoding\n",
    "    encoded_images = tf.placeholder(tf.string, [batch_size])\n",
    "    image_decoder = tf.reverse(tf.map_fn(lambda var: tf.cast(tf.image.decode_jpeg(var), tf.float32), \n",
    "                         encoded_images, dtype=tf.float32), [-1]) - tf.constant([[[[103.939, 116.779, 123.68]]]])\n",
    "    \n",
    "    # Declare optimizer\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, num_train // batch_size, learning_decay_rate, staircase=False)\n",
    "    train_step = tf.train.AdamOptimizer(2e-5).minimize(bb_net.loss, global_step=global_step)\n",
    "    \n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(iterator_train.initializer)\n",
    "    sess.run(iterator_val.initializer)\n",
    "    \n",
    "    # Train Loop\n",
    "    for i in range(num_iter):\n",
    "        next_example_train = sess.run(next_element_train)\n",
    "        try:\n",
    "            parsed_out = sess.run(parser, feed_dict={next_example: next_example_train})\n",
    "            \n",
    "            xmin = np.array(parsed_out['image/object/bbox/xmin'])\n",
    "            xmax = np.array(parsed_out['image/object/bbox/xmax'])\n",
    "            ymin = np.array(parsed_out['image/object/bbox/ymin'])\n",
    "            ymax = np.array(parsed_out['image/object/bbox/ymax'])\n",
    "            \n",
    "            if xmin.size == 0:\n",
    "                xmin = ymin = np.array(batch_size * [[-1.]])\n",
    "                xmax = ymax = np.array(batch_size * [[0.]])\n",
    "            \n",
    "            prob = list(map(lambda x: float(x[0] > -.5), xmin))\n",
    "            x = sess.run(tf.reverse(tf.map_fn(lambda var: tf.cast(tf.image.decode_jpeg(var), tf.float32), \n",
    "                                              parsed_out['image/encoded'], dtype=tf.float32), [-1]) - tf.constant([[[[103.939, 116.779, 123.68]]]]))\n",
    "            sess.run(train_step, feed_dict={images: x, train_mode: use_dropout, target_prob: prob, \n",
    "                                            target_bb: np.concatenate((xmin, ymin, np.log(xmax - xmin), np.log(ymax - ymin)), axis = 1)})\n",
    "        except Exception as ex:\n",
    "            err_file.write(ex + '\\n')\n",
    "        \n",
    "        # Log of learning progress (loss, acc, bb mean abs err)\n",
    "        if (i + 1) % log_every == 0:\n",
    "            loss_train = np.zeros(num_val)\n",
    "            acc_train = np.zeros(num_val)\n",
    "            bb_err_train = np.zeros(num_val)\n",
    "            loss_val = np.zeros(num_val)\n",
    "            acc_val = np.zeros(num_val)\n",
    "            bb_err_val = np.zeros(num_val)\n",
    "            sum_obj_train = 0\n",
    "            sum_obj_val = 0\n",
    "            for j in range(num_val):\n",
    "                next_example_val = sess.run(next_element_train)\n",
    "                try:\n",
    "                    parsed_out = sess.run(parser, feed_dict={next_example: next_example_val})\n",
    "\n",
    "                    xmin = np.array(parsed_out['image/object/bbox/xmin'])\n",
    "                    xmax = np.array(parsed_out['image/object/bbox/xmax'])\n",
    "                    ymin = np.array(parsed_out['image/object/bbox/ymin'])\n",
    "                    ymax = np.array(parsed_out['image/object/bbox/ymax'])\n",
    "\n",
    "                    if xmin.size == 0:\n",
    "                        xmin = ymin = np.array(batch_size * [[-1.]])\n",
    "                        xmax = ymax = np.array(batch_size * [[0.]])\n",
    "\n",
    "                    prob = np.array(list(map(lambda x: float(x[0] > -.5), xmin)))\n",
    "\n",
    "                    x = sess.run(image_decoder, feed_dict={encoded_images: parsed_out['image/encoded']})\n",
    "                    net_prob = sess.run(bb_net.pred_prob, feed_dict={images: x, train_mode: False})\n",
    "                    acc_train[j] = np.mean(np.abs(prob - 1. * (net_prob < .5)))\n",
    "                    net_bb = sess.run(bb_net.pred_bb, feed_dict={images: x, train_mode: False})\n",
    "                    bb_err_train[j] = np.sum(prob * np.mean(np.abs(np.concatenate((xmin, ymin, xmax - xmin, ymax - ymin), axis = 1) - net_bb), 1))\n",
    "                    sum_obj_train += np.sum(prob)\n",
    "                    loss_train[j] = sess.run(bb_net.loss, feed_dict={images: x, train_mode: False, target_prob: prob, \n",
    "                                                                       target_bb: np.concatenate((xmin, ymin, np.log(xmax - xmin), np.log(ymax - ymin)), axis = 1)})\n",
    "                except Exception as ex:\n",
    "                    err_file.write(ex + '\\n')\n",
    "                \n",
    "                next_example_val = sess.run(next_element_val)\n",
    "                try:\n",
    "                    parsed_out = sess.run(parser, feed_dict={next_example: next_example_val})\n",
    "\n",
    "                    xmin = np.array(parsed_out['image/object/bbox/xmin'])\n",
    "                    xmax = np.array(parsed_out['image/object/bbox/xmax'])\n",
    "                    ymin = np.array(parsed_out['image/object/bbox/ymin'])\n",
    "                    ymax = np.array(parsed_out['image/object/bbox/ymax'])\n",
    "\n",
    "                    if xmin.size == 0:\n",
    "                        xmin = ymin = np.array(batch_size * [[-1.]])\n",
    "                        xmax = ymax = np.array(batch_size * [[0.]])\n",
    "\n",
    "                    prob = np.array(list(map(lambda x: float(x[0] > -.5), xmin)))\n",
    "\n",
    "                    x = sess.run(image_decoder, feed_dict={encoded_images: parsed_out['image/encoded']})\n",
    "                    net_prob = sess.run(bb_net.pred_prob, feed_dict={images: x, train_mode: False})\n",
    "                    acc_val[j] = np.mean(np.abs(prob - 1. * (net_prob < .5)))\n",
    "                    net_bb = sess.run(bb_net.pred_bb, feed_dict={images: x, train_mode: False})\n",
    "                    bb_err_val[j] = np.sum(prob * np.mean(np.abs(np.concatenate((xmin, ymin, xmax - xmin, ymax - ymin), axis = 1) - net_bb), 1))\n",
    "                    sum_obj_val += np.sum(prob)\n",
    "                    loss_val[j] = sess.run(bb_net.loss, feed_dict={images: x, train_mode: False, target_prob: prob, \n",
    "                                                                       target_bb: np.concatenate((xmin, ymin, np.log(xmax - xmin), np.log(ymax - ymin)), axis = 1)})\n",
    "                except Exception as ex:\n",
    "                    err_file.write(ex + '\\n')\n",
    "                    \n",
    "            if sum_obj_train == 0:\n",
    "                mean_bb_err_train = 0.\n",
    "            else:\n",
    "                mean_bb_err_train = np.sum(bb_err_train) / sum_obj_train\n",
    "            if sum_obj_val == 0:\n",
    "                mean_bb_err_val = 0.\n",
    "            else:\n",
    "                mean_bb_err_val = np.sum(bb_err_val) / sum_obj_val\n",
    "                \n",
    "            log_file.write(str(i + 1) + ',' + str(np.mean(loss_train)) + ',' + str(np.mean(acc_train)) + ',' + str(mean_bb_err_train) + ',' + str(np.mean(loss_val)) + ',' + str(np.mean(acc_val)) + ',' + str(mean_bb_err_val) + '\\n')\n",
    "        \n",
    "        # Save trained model\n",
    "        if (i + 1) % save_every == 0:\n",
    "            bb_net.save(sess, './bb_cnn_vgg16_' + ('%02i' % ((i + 1) // save_every)) + '.npy')\n",
    "            \n",
    "log_file.close()\n",
    "err_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
